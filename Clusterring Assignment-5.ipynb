{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60f819-baee-445d-b079-c3f00fc849a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. \n",
    "A contingency matrix is a table that describes the performance of a classification model by comparing predicted and actual class labels. It has rows representing actual classes and columns representing predicted classes. Each cell counts the number of instances belonging to a specific combination of actual and predicted classes. It's used to calculate various evaluation metrics.\n",
    "\n",
    "2. \n",
    "A pair confusion matrix is a type of confusion matrix that focuses on pairwise comparisons of classes. It's useful in situations where specific class pairs are of particular interest or concern. It provides a more detailed view of how well a model distinguishes between specific classes.\n",
    "\n",
    "3. \n",
    "An extrinsic measure in natural language processing typically involves evaluating a model's performance on a downstream task, such as sentiment analysis or named entity recognition. It assesses how well the model's output contributes to the performance of the broader task.\n",
    "\n",
    "4. \n",
    "An intrinsic measure in machine learning focuses on evaluating the performance of a model without considering its impact on a specific downstream task. It assesses the model's capabilities in isolation, often through metrics like precision, recall, or F1 score.\n",
    "\n",
    "5. \n",
    "The confusion matrix in machine learning serves the purpose of summarizing the performance of a classification model. It helps identify strengths (correctly classified instances on the diagonal) and weaknesses (off-diagonal entries representing misclassifications) of the model. It's a foundation for various metrics like accuracy, precision, recall, and F1 score.\n",
    "\n",
    "6. \n",
    "Common intrinsic measures for unsupervised learning include silhouette score, Davies-Bouldin index, and inter-cluster distance. They help assess the quality of clusters and the compactness/separation of data points within clusters.\n",
    "\n",
    "7.\n",
    "Limitations of using accuracy as a sole evaluation metric:\n",
    "Doesn't account for class imbalances.\n",
    "Ignores the costs of different types of errors.\n",
    "Unsuitable for skewed datasets.\n",
    "Addressing limitations:\n",
    "Use precision, recall, F1 score, or area under the ROC curve (AUC-ROC) for a more comprehensive evaluation.\n",
    "Consider domain-specific metrics or a combination of metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
